# ğŸ§ iask_me â€” Audio Processing with Generative AI

**iask_me** es un sistema de procesamiento de audio impulsado por **inteligencia artificial generativa (GenAI)**.  
Su objetivo es transformar audios en texto Ãºtil y comprensible, permitiendo generar preguntas, traducciones y resÃºmenes automÃ¡ticos del contenido transcrito.

---

## ğŸš€ DescripciÃ³n general

El proyecto estÃ¡ diseÃ±ado para **convertir audio en texto** mediante modelos de IA y ofrecer una **interfaz inteligente de consulta** sobre los datos obtenidos.  
Permite a los usuarios subir archivos de audio, transcribirlos automÃ¡ticamente y generar respuestas o resÃºmenes con modelos de lenguaje.

---

## ğŸ§  Modelos de IA utilizados

| Tarea | Modelo | DescripciÃ³n |
|-------|---------|-------------|
| **TranscripciÃ³n de audio** | ğŸ—£ï¸ `Whisper-1` (OpenAI) | Modelo de reconocimiento automÃ¡tico de voz (ASR) utilizado para convertir audio en texto. |
| **TraducciÃ³n y resumen** | ğŸ’¬ `GPT-4` (OpenAI) | Modelo generativo de lenguaje usado para traducir y sintetizar la informaciÃ³n transcrita. |

**ğŸ‘‰ En resumen:**  
Todas las **peticiones de transcripciÃ³n** en `iask_me` usan el modelo **Whisper-1**, mientras que las **peticiones de traducciÃ³n o resumen** usan **GPT-4**.

---

## âš™ï¸ Endpoints principales (segÃºn `swagger.yaml`)

| Endpoint | MÃ©todo | DescripciÃ³n |
|-----------|---------|-------------|
| `/upload` | `POST` | Subida de archivo de audio. |
| `/transcribe/{job_id}` | `POST` | TranscripciÃ³n con Whisper-1. |
| `/translate/{job_id}` | `POST` | TraducciÃ³n generativa. |
| `/summarize/{job_id}` | `POST` | Resumen del contenido transcrito. |
| `/jobs/{job_id}` | `GET` | Estado del procesamiento. |

---

## ğŸ§© Arquitectura del sistema

- **Frontend:** Interfaz web para subir y consultar audios.
- **Backend:** API REST documentada en [`swagger.yaml`](./swagger.yaml).
- **Motor de IA:** Whisper-1 + GPT-4.
- **Almacenamiento:** Base de datos vectorial para bÃºsquedas semÃ¡nticas.
- **Infraestructura:** Docker + Python + FastAPI.

---

## ğŸ§ª Ejemplo de flujo

1. El usuario sube un archivo de audio (`/upload`).
2. El sistema lo transcribe con **Whisper-1** (`/transcribe`).
3. El texto resultante se traduce o resume usando **GPT-4**.
4. Las respuestas se almacenan en una base vectorial para futuras consultas.

---

## ğŸ§° TecnologÃ­as principales

- Python 3.10+
- FastAPI
- OpenAI Whisper
- OpenAI GPT-4
- Docker
- FAISS / ChromaDB

---

## ğŸ“„ Licencia
Este proyecto se distribuye bajo licencia MIT.

---

## ğŸ‘©â€ğŸ’» Autora
**Isabel Najarro** â€” [GitHub: isabelnajarro](https://github.com/isabelnajarro)

---

### ğŸ—£ï¸ Nota para desarrolladores
Si utilizas este proyecto desde el **orchestrator**, recuerda que las peticiones usan:
- **`Whisper-1`** para transcripciÃ³n de audio  
- **`GPT-4`** para generaciÃ³n de texto, traducciÃ³n y resumen
